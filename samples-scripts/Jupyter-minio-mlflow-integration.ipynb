{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c6b946",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✅ {package} installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Failed to install {package}: {e}\")\n",
    "\n",
    "# Install required packages\n",
    "packages = [\n",
    "    \"mlflow\",\n",
    "    \"scikit-learn\", \n",
    "    \"pandas\",\n",
    "    \"numpy\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"boto3\",  # For S3/MinIO interaction\n",
    "    \"minio\"   # MinIO Python client\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e46f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Import libraries and setup\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "import os\n",
    "import requests\n",
    "from minio import Minio\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd232cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3: Configure MLflow and test connectivity\n",
    "# Set MLflow tracking URI to your MLflow server\n",
    "mlflow.set_tracking_uri(\"http://mlflow.local\")\n",
    "\n",
    "# Test MLflow connectivity\n",
    "try:\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiments = client.search_experiments()\n",
    "    print(f\"✅ MLflow connection successful! Found {len(experiments)} experiments\")\n",
    "    print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ MLflow connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35a66a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4: Test MinIO connectivity\n",
    "# Test MinIO connection\n",
    "try:\n",
    "    # Using boto3 (S3-compatible)\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url='http://minio.minio:9000',\n",
    "        aws_access_key_id='minioadmin',\n",
    "        aws_secret_access_key='minioadmin',\n",
    "        config=Config(signature_version='s3v4'),\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "    \n",
    "    # List buckets\n",
    "    buckets = s3_client.list_buckets()\n",
    "    print(\"✅ MinIO connection successful!\")\n",
    "    print(\"Available buckets:\")\n",
    "    for bucket in buckets['Buckets']:\n",
    "        print(f\"  - {bucket['Name']}\")\n",
    "    \n",
    "    # Check if mlflow bucket exists\n",
    "    bucket_list = [bucket['Name'] for bucket in buckets['Buckets']]\n",
    "    if 'mlflow' not in bucket_list:\n",
    "        print(\"Creating 'mlflow' bucket...\")\n",
    "        s3_client.create_bucket(Bucket='mlflow')\n",
    "        print(\"✅ MLflow bucket created!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ MinIO connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88520953",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5: Test direct MinIO client\n",
    "try:\n",
    "    # Using MinIO Python client\n",
    "    minio_client = Minio(\n",
    "        'minio.minio:9000',\n",
    "        access_key='minioadmin',\n",
    "        secret_key='minioadmin',\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    # Test connection\n",
    "    if minio_client.bucket_exists('mlflow'):\n",
    "        print(\"✅ MLflow bucket exists in MinIO\")\n",
    "    else:\n",
    "        minio_client.make_bucket('mlflow')\n",
    "        print(\"✅ Created MLflow bucket in MinIO\")\n",
    "        \n",
    "    # Upload a test file\n",
    "    test_data = \"This is a test file for MLflow integration\"\n",
    "    with open('/tmp/test_file.txt', 'w') as f:\n",
    "        f.write(test_data)\n",
    "    \n",
    "    minio_client.fput_object('mlflow', 'test/test_file.txt', '/tmp/test_file.txt')\n",
    "    print(\"✅ Test file uploaded to MinIO\")\n",
    "    \n",
    "    # List objects in mlflow bucket\n",
    "    objects = minio_client.list_objects('mlflow', recursive=True)\n",
    "    print(\"Objects in mlflow bucket:\")\n",
    "    for obj in objects:\n",
    "        print(f\"  - {obj.object_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ MinIO client error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc0a56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6: Generate sample dataset\n",
    "# Create a synthetic dataset for our ML experiment\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=8,\n",
    "    n_redundant=2,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(f\"✅ Dataset created with shape: {df.shape}\")\n",
    "print(f\"Target distribution:\\n{df['target'].value_counts()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50280774",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: Exploratory Data Analysis\n",
    "# Create some plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Feature correlation heatmap\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[0,0])\n",
    "axes[0,0].set_title('Feature Correlation Heatmap')\n",
    "\n",
    "# Target distribution\n",
    "df['target'].value_counts().plot(kind='bar', ax=axes[0,1])\n",
    "axes[0,1].set_title('Target Distribution')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "\n",
    "# Feature distributions\n",
    "df[['feature_0', 'feature_1', 'feature_2']].hist(bins=20, ax=axes[1,0])\n",
    "axes[1,0].set_title('Feature Distributions (First 3 features)')\n",
    "\n",
    "# Scatter plot\n",
    "scatter = axes[1,1].scatter(df['feature_0'], df['feature_1'], c=df['target'], cmap='viridis', alpha=0.6)\n",
    "axes[1,1].set_xlabel('Feature 0')\n",
    "axes[1,1].set_ylabel('Feature 1')\n",
    "axes[1,1].set_title('Feature 0 vs Feature 1 (colored by target)')\n",
    "plt.colorbar(scatter, ax=axes[1,1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ EDA plots generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1163d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8: MLflow Experiment Setup (CORRECTED)\n",
    "import mlflow\n",
    "\n",
    "# Create a new experiment\n",
    "experiment_name = \"jupyter-minio-integration-test\"\n",
    "\n",
    "try:\n",
    "    # First, check if experiment already exists\n",
    "    try:\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is not None:\n",
    "            experiment_id = experiment.experiment_id\n",
    "            print(f\"✅ Using existing experiment: {experiment_name} (ID: {experiment_id})\")\n",
    "        else:\n",
    "            raise mlflow.exceptions.MlflowException(\"Experiment not found\")\n",
    "    except:\n",
    "        # Create new experiment if it doesn't exist\n",
    "        experiment_id = mlflow.create_experiment(\n",
    "            experiment_name,\n",
    "            artifact_location=f\"s3://mlflow/experiments/{experiment_name}\"\n",
    "        )\n",
    "        print(f\"✅ Created new experiment: {experiment_name} (ID: {experiment_id})\")\n",
    "    \n",
    "    # Set the experiment - this is crucial!\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Verify the experiment is set correctly\n",
    "    current_experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    print(f\"Current active experiment: {current_experiment.name} (ID: {current_experiment.experiment_id})\")\n",
    "    print(f\"Artifact location: {current_experiment.artifact_location}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error with experiment setup: {e}\")\n",
    "    # Fallback: use default experiment\n",
    "    print(\"Using default experiment instead...\")\n",
    "    mlflow.set_experiment(\"Default\")\n",
    "    current_experiment = mlflow.get_experiment_by_name(\"Default\")\n",
    "    print(f\"Using experiment: {current_experiment.name} (ID: {current_experiment.experiment_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc758599-03d8-4937-bdda-53826f1bdef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: MLflow Setup with S3\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "# Set environment variables for S3/MinIO access\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://minio.minio.svc.cluster.local:9000'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'minioadmin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'minioadmin'\n",
    "os.environ['AWS_S3_FORCE_PATH_STYLE'] = 'true'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "\n",
    "print(\"✅ S3/MinIO environment variables set\")\n",
    "\n",
    "# Set MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\"http://mlflow.local\")\n",
    "\n",
    "# Test basic connectivity first\n",
    "try:\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiments = client.search_experiments()\n",
    "    print(f\"✅ MLflow server connected. Found {len(experiments)} experiments\")\n",
    "    \n",
    "    # Use default experiment but set artifact location properly\n",
    "    mlflow.set_experiment(\"Default\")\n",
    "    \n",
    "    # Get current experiment info\n",
    "    current_exp = mlflow.get_experiment_by_name(\"Default\")\n",
    "    print(f\"Using experiment: {current_exp.name} (ID: {current_exp.experiment_id})\")\n",
    "    print(f\"Artifact location: {current_exp.artifact_location}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ MLflow setup error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa343246",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 9: Train and log models with MLflow\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def train_and_log_model(model, model_name, params):\n",
    "    \"\"\"Train a model and log it with MLflow\"\"\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"{model_name}_run\") as run:\n",
    "        print(f\"\\n🚀 Training {model_name}...\")\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"train_samples\", len(X_train))\n",
    "        mlflow.log_metric(\"test_samples\", len(X_test))\n",
    "        \n",
    "        print(f\"✅ {model_name} Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(\n",
    "            model, \n",
    "            model_name.lower(),\n",
    "            registered_model_name=f\"{model_name}_Model\"\n",
    "        )\n",
    "        \n",
    "        # Create and log confusion matrix plot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'{model_name} Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot to file and log as artifact\n",
    "        plot_path = f\"/tmp/{model_name.lower()}_confusion_matrix.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        mlflow.log_artifact(plot_path)\n",
    "        plt.show()\n",
    "        \n",
    "        # Log feature importance (if available)\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
    "            plt.title(f'{model_name} Feature Importance (Top 10)')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            importance_path = f\"/tmp/{model_name.lower()}_feature_importance.png\"\n",
    "            plt.savefig(importance_path)\n",
    "            mlflow.log_artifact(importance_path)\n",
    "            plt.show()\n",
    "            \n",
    "            # Log feature importance as CSV\n",
    "            importance_csv_path = f\"/tmp/{model_name.lower()}_feature_importance.csv\"\n",
    "            feature_importance.to_csv(importance_csv_path, index=False)\n",
    "            mlflow.log_artifact(importance_csv_path)\n",
    "        \n",
    "        # Log classification report\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric_name, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric_name}\", value)\n",
    "        \n",
    "        print(f\"✅ {model_name} logged to MLflow with run ID: {run.info.run_id}\")\n",
    "        \n",
    "        return model, accuracy\n",
    "\n",
    "# Train Random Forest\n",
    "rf_params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_trained, rf_accuracy = train_and_log_model(rf_model, \"RandomForest\", rf_params)\n",
    "\n",
    "# Train Logistic Regression\n",
    "lr_params = {\n",
    "    \"random_state\": 42,\n",
    "    \"max_iter\": 1000\n",
    "}\n",
    "lr_model = LogisticRegression(**lr_params)\n",
    "lr_trained, lr_accuracy = train_and_log_model(lr_model, \"LogisticRegression\", lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49113a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 10: Compare models and log comparison\n",
    "# Create model comparison\n",
    "comparison_data = {\n",
    "    'Model': ['RandomForest', 'LogisticRegression'],\n",
    "    'Accuracy': [rf_accuracy, lr_accuracy]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Model Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=comparison_df, x='Model', y='Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(comparison_df['Accuracy']):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Log comparison as artifact\n",
    "comparison_path = \"/tmp/model_comparison.png\"\n",
    "plt.savefig(comparison_path)\n",
    "plt.show()\n",
    "\n",
    "# Log the comparison in a new run\n",
    "with mlflow.start_run(run_name=\"model_comparison\") as run:\n",
    "    mlflow.log_artifact(comparison_path)\n",
    "    mlflow.log_metric(\"best_accuracy\", max(rf_accuracy, lr_accuracy))\n",
    "    mlflow.log_param(\"best_model\", \"RandomForest\" if rf_accuracy > lr_accuracy else \"LogisticRegression\")\n",
    "    \n",
    "    # Save comparison CSV and log it\n",
    "    comparison_csv_path = \"/tmp/model_comparison.csv\"\n",
    "    comparison_df.to_csv(comparison_csv_path, index=False)\n",
    "    mlflow.log_artifact(comparison_csv_path)\n",
    "    \n",
    "    print(f\"✅ Model comparison logged with run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920f1b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 11: Test model loading and prediction\n",
    "# Load the best model from MLflow\n",
    "best_model_name = \"RandomForest\" if rf_accuracy > lr_accuracy else \"LogisticRegression\"\n",
    "print(f\"Loading best model: {best_model_name}\")\n",
    "\n",
    "try:\n",
    "    # Get the latest version of the model\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    model_versions = client.search_model_versions(f\"name='{best_model_name}_Model'\")\n",
    "    latest_version = max([int(mv.version) for mv in model_versions])\n",
    "    \n",
    "    # Load model\n",
    "    model_uri = f\"models:/{best_model_name}_Model/{latest_version}\"\n",
    "    loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "    \n",
    "    print(f\"✅ Loaded {best_model_name} model version {latest_version}\")\n",
    "    \n",
    "    # Make predictions with loaded model\n",
    "    sample_predictions = loaded_model.predict(X_test[:5])\n",
    "    actual_values = y_test[:5]\n",
    "    \n",
    "    print(\"\\nSample predictions vs actual:\")\n",
    "    for i, (pred, actual) in enumerate(zip(sample_predictions, actual_values)):\n",
    "        print(f\"Sample {i+1}: Predicted={pred}, Actual={actual}, Match={'✅' if pred==actual else '❌'}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab6164",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 12: Verify artifacts in MinIO\n",
    "print(\"🔍 Checking artifacts stored in MinIO...\")\n",
    "\n",
    "try:\n",
    "    # List all objects in the mlflow bucket\n",
    "    objects = minio_client.list_objects('mlflow', recursive=True)\n",
    "    artifact_count = 0\n",
    "    \n",
    "    print(\"\\nArtifacts in MinIO (mlflow bucket):\")\n",
    "    for obj in objects:\n",
    "        print(f\"  📁 {obj.object_name} ({obj.size} bytes)\")\n",
    "        artifact_count += 1\n",
    "    \n",
    "    print(f\"\\n✅ Total artifacts stored: {artifact_count}\")\n",
    "    \n",
    "    # Download a sample artifact to verify\n",
    "    if artifact_count > 0:\n",
    "        try:\n",
    "            # Try to download a model file\n",
    "            sample_object = next(minio_client.list_objects('mlflow', recursive=True))\n",
    "            local_path = f\"/tmp/downloaded_{sample_object.object_name.split('/')[-1]}\"\n",
    "            minio_client.fget_object('mlflow', sample_object.object_name, local_path)\n",
    "            print(f\"✅ Successfully downloaded sample artifact: {sample_object.object_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not download sample artifact: {e}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error accessing MinIO: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3941a02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 13: Integration Summary and Health Check\n",
    "print(\"🎉 INTEGRATION TEST SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check each component\n",
    "components = {\n",
    "    \"JupyterHub\": \"✅ Running (you're using it now!)\",\n",
    "    \"MLflow\": None,\n",
    "    \"MinIO\": None\n",
    "}\n",
    "\n",
    "# Test MLflow\n",
    "try:\n",
    "    experiments = mlflow.search_experiments()\n",
    "    components[\"MLflow\"] = f\"✅ Connected - {len(experiments)} experiments found\"\n",
    "except:\n",
    "    components[\"MLflow\"] = \"❌ Connection failed\"\n",
    "\n",
    "# Test MinIO\n",
    "try:\n",
    "    buckets = minio_client.list_buckets()\n",
    "    bucket_count = len(list(buckets))\n",
    "    components[\"MinIO\"] = f\"✅ Connected - {bucket_count} buckets available\"\n",
    "except:\n",
    "    components[\"MinIO\"] = \"❌ Connection failed\"\n",
    "\n",
    "# Print results\n",
    "for component, status in components.items():\n",
    "    print(f\"{component:12}: {status}\")\n",
    "\n",
    "print(\"\\n📊 EXPERIMENT RESULTS:\")\n",
    "print(f\"  • Trained {2} models\")\n",
    "print(f\"  • Best accuracy: {max(rf_accuracy, lr_accuracy):.4f}\")\n",
    "print(f\"  • Artifacts stored in MinIO: ✅\")\n",
    "print(f\"  • Models registered in MLflow: ✅\")\n",
    "\n",
    "print(f\"\\n🌐 ACCESS URLS:\")\n",
    "print(f\"  • JupyterHub: http://jupyter.local\")\n",
    "print(f\"  • MLflow UI: http://mlflow.local\")\n",
    "print(f\"  • MinIO Console: http://minio-console.local\")\n",
    "\n",
    "print(f\"\\n🔗 Next Steps:\")\n",
    "print(f\"  1. Visit MLflow UI to explore your experiments\")\n",
    "print(f\"  2. Check MinIO console to see stored artifacts\")\n",
    "print(f\"  3. Try loading and using your models in other notebooks\")\n",
    "print(f\"  4. Experiment with different ML algorithms and parameters\")\n",
    "\n",
    "print(f\"\\n✅ Integration test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27213675-c28c-457e-8d04-6c5cdb4edea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
