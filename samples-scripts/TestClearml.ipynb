{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5fedcf-f9b9-4594-be9a-3be466ccfd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install clearml[s3] scikit-learn matplotlib seaborn numpy joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba35a46-903e-42eb-8a7e-9db1e749e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CLEARML_API_HOST_VERIFY_CERT'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70799e3-015b-4359-9e56-f1cf03d00100",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clearml.local/\n",
    "%env CLEARML_API_HOST=https://api.clearml.local\n",
    "%env CLEARML_FILES_HOST=https://files.clearml.local/\n",
    "%env CLEARML_API_ACCESS_KEY= 5PLP7V91SFS0MF244GEBS9W40PVKJQ\n",
    "%env CLEARML_API_SECRET_KEY= 3gh_KKZT0SyFpl7MZ2VQMv_fQ_JaZyV-eyCyVDDMwtX2Qf62ioJVFtOPg5mv6UKodak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e774c0e-6169-4226-878e-dca60f5ac402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from clearml import Task, Logger\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "CLEARML_SERVER = \"https://api.clearml.local\"\n",
    "CLEARML_WEB_SERVER = \"https://app.clearml.local\"\n",
    "CLEARML_FILES_SERVER = \"https://files.clearml.local\"\n",
    "\n",
    "# MinIO configuration for model storage\n",
    "MINIO_ENDPOINT = \"minio.local:80\"\n",
    "MODEL_BUCKET = \"clearml-artifacts\"  # Make sure this bucket exists in MinIO\n",
    "\n",
    "def test_clearml_storage(task):\n",
    "    \"\"\"\n",
    "    Test ClearML installation by:\n",
    "    1. Creating plots that should go to fileserver\n",
    "    2. Saving models that should go to MinIO\n",
    "    3. Logging metrics and scalars\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize ClearML Task\n",
    "    print(\"Initializing ClearML Task...\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get the logger for plots\n",
    "    logger = task.get_logger()\n",
    "    \n",
    "    # Log some configuration parameters\n",
    "    task.connect({\n",
    "        'test_param_1': 42,\n",
    "        'test_param_2': 'hello_clearml',\n",
    "        'learning_rate': 0.01,\n",
    "        'epochs': 100,\n",
    "        'batch_size': 32\n",
    "    })\n",
    "    \n",
    "    print(\"\\n1. Testing scalar logging...\")\n",
    "    # Log some scalar metrics (these go to MongoDB/Elasticsearch)\n",
    "    for i in range(10):\n",
    "        logger.report_scalar(\n",
    "            title='test_metrics',\n",
    "            series='accuracy',\n",
    "            value=np.random.random() * 0.3 + 0.7,\n",
    "            iteration=i\n",
    "        )\n",
    "        logger.report_scalar(\n",
    "            title='test_metrics',\n",
    "            series='loss',\n",
    "            value=np.random.random() * 0.5,\n",
    "            iteration=i\n",
    "        )\n",
    "        logger.report_scalar(\n",
    "            title='learning_curves',\n",
    "            series='train_loss',\n",
    "            value=1.0 - (i * 0.1) + np.random.random() * 0.1,\n",
    "            iteration=i\n",
    "        )\n",
    "        logger.report_scalar(\n",
    "            title='learning_curves',\n",
    "            series='val_loss',\n",
    "            value=1.2 - (i * 0.08) + np.random.random() * 0.15,\n",
    "            iteration=i\n",
    "        )\n",
    "    print(\"✓ Scalar metrics logged\")\n",
    "    \n",
    "    print(\"\\n2. Testing plot/image storage (should go to fileserver)...\")\n",
    "    \n",
    "    # Create and log a matplotlib plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Plot 1: Line plot\n",
    "    x = np.linspace(0, 10, 100)\n",
    "    axes[0, 0].plot(x, np.sin(x), label='sin(x)')\n",
    "    axes[0, 0].plot(x, np.cos(x), label='cos(x)')\n",
    "    axes[0, 0].set_title('Trigonometric Functions')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Plot 2: Scatter plot\n",
    "    x_scatter = np.random.randn(100)\n",
    "    y_scatter = 2 * x_scatter + np.random.randn(100) * 0.5\n",
    "    axes[0, 1].scatter(x_scatter, y_scatter, alpha=0.5)\n",
    "    axes[0, 1].set_title('Random Scatter')\n",
    "    axes[0, 1].set_xlabel('X values')\n",
    "    axes[0, 1].set_ylabel('Y values')\n",
    "    \n",
    "    # Plot 3: Histogram\n",
    "    data = np.random.randn(1000)\n",
    "    axes[1, 0].hist(data, bins=30, edgecolor='black')\n",
    "    axes[1, 0].set_title('Normal Distribution')\n",
    "    axes[1, 0].set_xlabel('Value')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Plot 4: Bar plot\n",
    "    categories = ['A', 'B', 'C', 'D', 'E']\n",
    "    values = np.random.randint(10, 100, 5)\n",
    "    axes[1, 1].bar(categories, values, color=['red', 'green', 'blue', 'yellow', 'purple'])\n",
    "    axes[1, 1].set_title('Category Comparison')\n",
    "    axes[1, 1].set_ylabel('Values')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    logger.report_matplotlib_figure(\n",
    "        title='Test Plots',\n",
    "        series='combined_plots',\n",
    "        figure=fig,\n",
    "        iteration=0\n",
    "    )\n",
    "    plt.close()\n",
    "    print(\"✓ Matplotlib plots logged\")\n",
    "    \n",
    "    # Create and log a confusion matrix\n",
    "    print(\"\\n3. Creating ML model and confusion matrix...\")\n",
    "    \n",
    "    # Generate synthetic dataset\n",
    "    X, y = make_classification(\n",
    "        n_samples=1000,\n",
    "        n_features=20,\n",
    "        n_informative=15,\n",
    "        n_redundant=5,\n",
    "        n_classes=3,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train a simple model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Log accuracy\n",
    "    logger.report_single_value('test_accuracy', accuracy)\n",
    "    print(f\"✓ Model trained with accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Create and log confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    logger.report_matplotlib_figure(\n",
    "        title='Model Performance',\n",
    "        series='confusion_matrix',\n",
    "        figure=plt.gcf(),\n",
    "        iteration=0\n",
    "    )\n",
    "    plt.close()\n",
    "    print(\"✓ Confusion matrix logged\")\n",
    "    \n",
    "    # Log classification report as text\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    logger.report_text(\n",
    "        \"Classification Report:\\n\" + report,\n",
    "        print_console=False\n",
    "    )\n",
    "    \n",
    "    print(\"\\n4. Testing model storage (should go to MinIO)...\")\n",
    "    \n",
    "    # Save the model locally first\n",
    "    model_filename = 'test_model.pkl'\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"✓ Model saved locally as {model_filename}\")\n",
    "    \n",
    "    # Register the model with ClearML (this should upload to MinIO)\n",
    "    task.update_output_model(\n",
    "        model_path=model_filename,\n",
    "        model_name='test_random_forest',\n",
    "        iteration=0,\n",
    "        comment='Test model for storage validation'\n",
    "    )\n",
    "    print(f\"✓ Model registered and should be uploaded\")\n",
    "    \n",
    "    # Log some additional images\n",
    "    print(\"\\n5. Testing multiple image formats...\")\n",
    "    \n",
    "    # Create a simple image array\n",
    "    image_array = np.random.rand(100, 100, 3)\n",
    "    logger.report_image(\n",
    "        title='Random Images',\n",
    "        series='random_rgb',\n",
    "        iteration=0,\n",
    "        image=image_array\n",
    "    )\n",
    "    \n",
    "    # Create a grayscale image\n",
    "    gray_image = np.random.rand(100, 100)\n",
    "    logger.report_image(\n",
    "        title='Random Images',\n",
    "        series='random_grayscale',\n",
    "        iteration=0,\n",
    "        image=gray_image\n",
    "    )\n",
    "    print(\"✓ Additional images logged\")\n",
    "    \n",
    "    # Log some console output\n",
    "    print(\"\\n6. Testing console logging...\")\n",
    "    print(\"This is a test console output\")\n",
    "    print(\"It should appear in the ClearML console logs\")\n",
    "    for i in range(5):\n",
    "        print(f\"  Progress: {i+1}/5\")\n",
    "        time.sleep(0.5)\n",
    "    print(\"✓ Console logging complete\")\n",
    "    \n",
    "    # Create a summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STORAGE TEST SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Task ID: {task.id}\")\n",
    "    print(f\"Task Name: {task.name}\")\n",
    "    print(f\"Project: {task.get_project_name()}\")\n",
    "    print(f\"\\nExpected storage locations:\")\n",
    "    print(f\"  - Plots/Images: {CLEARML_FILES_SERVER}\")\n",
    "    print(f\"  - Model: s3://{MINIO_ENDPOINT}/{MODEL_BUCKET}\")\n",
    "    print(f\"  - Metrics/Logs: MongoDB/Elasticsearch (internal)\")\n",
    "    print(\"\\nYou can verify the results at:\")\n",
    "    print(f\"  Web UI: {CLEARML_WEB_SERVER}\")\n",
    "    print(f\"  Direct link: {CLEARML_WEB_SERVER}/projects/{task.get_project_id(task.get_project_name())}/experiments/{task.id}\")\n",
    "    \n",
    "    # Clean up local model file\n",
    "    if os.path.exists(model_filename):\n",
    "        os.remove(model_filename)\n",
    "        print(f\"\\n✓ Cleaned up local model file: {model_filename}\")\n",
    "    \n",
    "    print(\"\\n✅ All tests completed successfully!\")\n",
    "    \n",
    "    return task\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    try:\n",
    "        task = Task.init(\n",
    "            project_name='storage_test',\n",
    "            task_name=f'test_storage_{time.strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "            tags=['test', 'storage-validation','test-tag'],\n",
    "            reuse_last_task_id=True,\n",
    "            output_uri=f\"s3://{MINIO_ENDPOINT}/{MODEL_BUCKET}\" \n",
    "        )\n",
    "        test_clearml_storage(task)\n",
    "        print(\"\\n🎉 Test completed! Check your ClearML Web UI to verify the results.\")\n",
    "        task.close()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during testing: {str(e)}\")\n",
    "        task.close()\n",
    "        print(\"\\nTroubleshooting tips:\")\n",
    "        print(\"1. Verify ClearML server is running: kubectl get pods -n <your-namespace>\")\n",
    "        print(\"2. Check ingress is working: kubectl get ingress -n <your-namespace>\")\n",
    "        print(\"3. Ensure DNS resolution for *.clearml.local domains\")\n",
    "        print(\"4. Verify MinIO is accessible and buckets exist\")\n",
    "        print(\"5. Check ClearML credentials are set correctly\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
